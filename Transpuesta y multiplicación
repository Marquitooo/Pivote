"""
Metodo del gradiente

Hecho por Marco Ramírez López
        y Jose Pablo Munoz Guerrero
"""

import numpy as np

#Tasa de aprendizaje
k=0.001
u=0.0001
itmax=100000

def printm(A):
    for i in range(len(A)):
        print(A[i])

def transponer(A):
    AT=[]
    for i in range(len(A)):
        aux=[]
        for j in range(len(A)):
            aux.append(A[j][i])
        AT.append(aux)
    return AT
        
def multM(A,b):
    C=[]
    for i in range(len(A)):
        for j in range(len(b)):
            x=0
            for k in range(len(A[0])):
                x=x+A[i][k]*b[k]
        C.append(x)
    return C

def multE(A,n):
    B=[]
    for i in range(len(A)):
        #Filtra los vectores de las matrices
        aux=[]
        if isinstance(A[0], list):
            for j in range(len(A[i])):
                x=A[i][j]
                aux.append(n*x)
            B.append(aux)
        else:
            B.append(n*A[i])
    return B

def resta(A,B):
    C=[]
    for i in range(len(A)):
        if isinstance(A[0],list):
            aux=[]
            for j in range(len(A[0])):
                aux.append(A[i][j]-B[i][j])
            C.append(aux)
        else:
            C.append(A[i]-B[i])
    return C

def gradient(x, A, b):
    e1=multM(transponer(A),multM(A, x))
    e2=multM(transponer(A),b)
    return resta(e1,e2)

def linear_solve(x_sol,A,b, umbral, itmax):  
    for i in range(itmax):
        x_sol=resta(x_sol,multE(gradient(x_sol,A,b),k))
        btent=multM(A,x_sol)
        error = np.sum(np.abs(resta(btent,b)))
        if error < umbral:
            return x_sol



x=[1.0,1.0,1.0]
A=[[2.0,1.0,-3.0],[5.0,-4.0,1.0],[1.0,-1.0,-4.0]]
b=[7.0,-19.0,4.0]


sol=linear_solve(x,A,b, u,itmax)
print("x:",sol)
print("b:",multM(A,sol))
